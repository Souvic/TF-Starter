{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, ssl\n",
    "if (not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None)): \n",
    "  ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_selector(x,y,batch_size,mode=\"random\"):\n",
    "    if(mode==\"random\"):\n",
    "        indices=np.random.choice(len(x),batch_size)\n",
    "        return(x[indices],y[indices],indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotit(y,labelx,labely,title):\n",
    "    plt.plot(y)\n",
    "    plt.xlabel(labelx)\n",
    "    plt.ylabel(labely)\n",
    "    plt.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__ (self,I,H,O):\n",
    "        self.I=I\n",
    "        self.H=H\n",
    "        self.O=O\n",
    "        self.W1 = tf.Variable(tf.random_normal([self.H[-1], self.O]))\n",
    "        self.b1 = tf.Variable(tf.ones([self.O]))\n",
    "        self.x_ = tf.placeholder(tf.float32, [None, self.I])\n",
    "        self.x=[self.x_]\n",
    "        self.W = [tf.Variable(tf.random_normal([self.I, self.H[0]]))]+[tf.Variable(tf.random_normal([self.H[HH], self.H[HH+1]])) for HH in range(len(self.H)-1)]\n",
    "        self.b = [tf.Variable(tf.ones([HH])) for HH in self.H]\n",
    "        for ii in range(len(self.H)):\n",
    "            self.x=self.x+[tf.nn.sigmoid(tf.matmul(self.x[-1], self.W[ii]) + self.b[ii])]\n",
    "\n",
    "        self.y_logit=tf.matmul(self.x[-1], self.W1) + self.b1\n",
    "        self.y = tf.nn.softmax(self.y_logit)\n",
    "        self.y_ = tf.placeholder(tf.float32, [None, self.O])\n",
    "        self.cross_entropy1 = (-tf.reduce_sum(self.y_ * tf.log(self.y), reduction_indices=[1]))\n",
    "        self.cross_entropy=tf.reduce_mean(self.cross_entropy1)\n",
    "        self.uninitialized_vars=None\n",
    "        self.train_step = tf.train.GradientDescentOptimizer(0.3).minimize(self.cross_entropy,var_list=self.uninitialized_vars)\n",
    "        self.correct_prediction = tf.equal(tf.argmax(self.y,1), tf.argmax(self.y_,1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_prediction, tf.float32))\n",
    "        self.WW = []\n",
    "        self.bb = []\n",
    "        self.WW1 = []\n",
    "        self.bb1 = []\n",
    "        self.xx=[[self.x_]]\n",
    "    def addh(self):\n",
    "        self.WW = self.WW+[[tf.Variable(tf.random_normal([self.I, self.H[0]]))]+[tf.Variable(tf.random_normal([self.H[HH], self.H[HH+1]])) for HH in range(len(self.H)-1)]]\n",
    "        self.bb = self.bb+[[tf.Variable(tf.ones([HH])) for HH in self.H]]\n",
    "        self.xx=self.xx+[[self.x_]]\n",
    "        for ii in range(len(self.H)):\n",
    "            self.xx[-1]=self.xx[-1]+[tf.nn.sigmoid(tf.matmul(self.xx[-1][-1], self.WW[-1][ii]) + self.bb[-1][ii])]\n",
    "        self.WW1 = self.WW1+[tf.Variable(tf.zeros([self.H[-1], self.O]))]\n",
    "        self.bb1 = self.bb1+[tf.Variable(tf.ones([self.O]))]\n",
    "        self.y_logit=self.y_logit+tf.matmul(self.xx[-1][-1], self.WW1[-1]) + self.bb1[-1]\n",
    "        uninitialized_vars = []\n",
    "        for var in tf.global_variables():\n",
    "            try:\n",
    "                sess.run(var)\n",
    "            except tf.errors.FailedPreconditionError:\n",
    "                uninitialized_vars.append(var)\n",
    "\n",
    "        init_new_vars_op = tf.variables_initializer(uninitialized_vars)\n",
    "        #sess.run(tf.variables_initializer(sess.run(tf.report_uninitialized_variables())))\n",
    "        sess.run(init_new_vars_op)\n",
    "        self.train_step = tf.train.GradientDescentOptimizer(0.3).minimize(self.cross_entropy,var_list=self.uninitialized_vars)\n",
    "        #tf.assign_add(self.y_logit,(tf.matmul(self.xx[-1][-1], self.WW1[-1]) + self.bb1[-1]))\n",
    "        #tf.variables_initializer((self.WW1[-1],self.bb1[-1],self.WW[-1],self.bb[-1]))\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff=NN(784,[16,16],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "batch_size=10;accumulator1=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys,indices = batch_selector(mnist.train.images,mnist.train.labels,batch_size,'random')\n",
    "    sess.run(ff.train_step, feed_dict={ff.x_: batch_xs, ff.y_: batch_ys})\n",
    "    if _%10==0:\n",
    "        accumulator1=accumulator1+[sess.run(ff.cross_entropy, feed_dict={ff.x_: mnist.train.images, ff.y_: mnist.train.labels})]\n",
    "\n",
    "        \n",
    "print(sess.run(ff.accuracy, feed_dict={ff.x_: mnist.test.images, ff.y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff.addh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.Session() as sess:\n",
    "   # batch_xs, batch_ys,indices = batch_selector(mnist.train.images,mnist.train.labels,batch_size,'random')\n",
    "  #  tf.global_variables_initializer().run()\n",
    "  #  writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "  #  print(sess.run(ff.train_step, feed_dict={ff.x_: batch_xs, ff.y_: batch_ys}))\n",
    "  #  writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys,indices = batch_selector(mnist.train.images,mnist.train.labels,batch_size,'random')\n",
    "    sess.run(ff.train_step, feed_dict={ff.x_: batch_xs, ff.y_: batch_ys})\n",
    "    if _%10==0:\n",
    "        accumulator1=accumulator1+[sess.run(ff.cross_entropy, feed_dict={ff.x_: mnist.train.images, ff.y_: mnist.train.labels})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(ff.accuracy, feed_dict={ff.x_: mnist.test.images, ff.y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff.addh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(1000):\n",
    "    batch_xs, batch_ys,indices = batch_selector(mnist.train.images,mnist.train.labels,batch_size,'random')\n",
    "    sess.run(ff.train_step, feed_dict={ff.x_: batch_xs, ff.y_: batch_ys})\n",
    "    if _%10==0:\n",
    "        accumulator1=accumulator1+[sess.run(ff.cross_entropy, feed_dict={ff.x_: mnist.train.images, ff.y_: mnist.train.labels})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sess.run(ff.accuracy, feed_dict={ff.x_: mnist.test.images, ff.y_: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotit(accumulator1,\"Number of iterations/10\",\"Training loss\",\"Training loss vs Training time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(ff.accuracy, feed_dict={ff.x_: mnist.test.images, ff.y_: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#concatenation not done yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
